{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<p style=\"align: center;\"><img align=center src=\"https://drive.google.com/uc?export=view&id=1I8kDikouqpH4hf7JBiSYAeNT2IO52T-T\" width=600 height=480/></p>\n<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n\n<h3 style=\"text-align: center;\"><b>Домашнее задание. Generative adversarial networks</b></h3>\n\n","metadata":{"id":"xG34LB_ov1SV"}},{"cell_type":"markdown","source":"В этом домашнем задании вы обучите GAN генерировать лица людей и посмотрите на то, как можно оценивать качество генерации","metadata":{"id":"JEZSpS6zv5BP"}},{"cell_type":"code","source":"from __future__ import print_function\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import LeaveOneOut, cross_val_score\nfrom sklearn.manifold import TSNE\nimport plotly.express as px\n\n# Set random seed for reproducibility\nmanualSeed = 777\nprint(\"Random Seed: \", manualSeed)\nrandom.seed(manualSeed)\ntorch.manual_seed(manualSeed)","metadata":{"id":"iIXHhd1ZvuSY","execution":{"iopub.status.busy":"2022-05-30T11:08:47.447112Z","iopub.execute_input":"2022-05-30T11:08:47.447432Z","iopub.status.idle":"2022-05-30T11:08:47.459374Z","shell.execute_reply.started":"2022-05-30T11:08:47.447395Z","shell.execute_reply":"2022-05-30T11:08:47.458295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataroot = '../input/faces-dataset-small'\nworkers = 2\nbatch_size = 16\nimage_size = 128\nnc = 3\nnz = 100\nnum_epochs = 20\nlr = 2e-4\nbeta1 = 0.5\n# Number of GPUs available. Use 0 for CPU mode.\nngpu = 1\n# Size of feature maps in generator\nngf = 64\n# Size of feature maps in discriminator\nndf = 32\n\nuse_pretrained = True","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:08:47.911707Z","iopub.execute_input":"2022-05-30T11:08:47.912211Z","iopub.status.idle":"2022-05-30T11:08:47.917441Z","shell.execute_reply.started":"2022-05-30T11:08:47.912174Z","shell.execute_reply":"2022-05-30T11:08:47.916468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Часть 1. Подготовка данных (1 балл)","metadata":{"id":"WrmSpt5e478V"}},{"cell_type":"markdown","source":"В качестве обучающей выборки возьмем часть датасета [Flickr Faces](https://github.com/NVlabs/ffhq-dataset), который содержит изображения лиц людей в высоком разрешении (1024х1024). Оригинальный датасет очень большой, поэтому мы возьмем его часть. Скачать датасет можно [здесь](https://drive.google.com/file/d/1KWPc4Pa7u2TWekUvNu9rTSO0U2eOlZA9/view?usp=sharing)","metadata":{"id":"Dp2fR2Jd2eoh"}},{"cell_type":"markdown","source":"Давайте загрузим наши изображения. Напишите функцию, которая строит DataLoader для изображений, при этом меняя их размер до нужного значения (размер 1024 слишком большой, поэтому мы рекомендуем взять размер 128 либо немного больше)","metadata":{"id":"s0uiO3Za40iK"}},{"cell_type":"code","source":"# We can use an image folder dataset the way we have it setup.\n# Create the dataset\ndataset = datasets.ImageFolder(root=dataroot,\n                               transform=transforms.Compose([\n                               transforms.Resize(image_size),\n                               transforms.CenterCrop(image_size),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ]))\n# Create the dataloader\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n                                         shuffle=True, num_workers=workers)\n\n# Decide which device we want to run on\ndevice = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n\n# Plot some training images\nreal_batch = next(iter(dataloader))\nplt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\nplt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:08:50.33805Z","iopub.execute_input":"2022-05-30T11:08:50.3383Z","iopub.status.idle":"2022-05-30T11:08:59.510301Z","shell.execute_reply.started":"2022-05-30T11:08:50.338273Z","shell.execute_reply":"2022-05-30T11:08:59.509354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Часть 2. Построение и обучение модели (2 балла)","metadata":{"id":"TgJiWnue5Aim"}},{"cell_type":"markdown","source":"Сконструируйте генератор и дискриминатор. Помните, что:\n* дискриминатор принимает на вход изображение (тензор размера `3 x image_size x image_size`) и выдает вероятность того, что изображение настоящее (тензор размера 1)\n\n* генератор принимает на вход тензор шумов размера `latent_size x 1 x 1` и генерирует изображение размера `3 x image_size x image_size`","metadata":{"id":"n00W_EXg72er"}},{"cell_type":"code","source":"# custom weights initialization called on netG and netD\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:08:59.512522Z","iopub.execute_input":"2022-05-30T11:08:59.512813Z","iopub.status.idle":"2022-05-30T11:08:59.519993Z","shell.execute_reply.started":"2022-05-30T11:08:59.512774Z","shell.execute_reply":"2022-05-30T11:08:59.519386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generator Code\n\nclass Generator(nn.Module):\n    def __init__(self, ngpu):\n        super(Generator, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            # input is Z, going into a convolution\n            nn.ConvTranspose2d(nz, ngf * 16, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 16),\n            nn.ReLU(True),\n            # state size. (ngf*16) x 4 x 4\n            nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            # state size. (ngf*8) x 8 x 8\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            # state size. (ngf*4) x 16 x 16 \n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # state size. (ngf*2) x 32 x 32\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # state size. (ngf) x 64 x 64\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n            # state size. (nc) x 128 x 128\n        )\n    def forward(self, input):\n        return self.main(input)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:08:59.521132Z","iopub.execute_input":"2022-05-30T11:08:59.522699Z","iopub.status.idle":"2022-05-30T11:08:59.54365Z","shell.execute_reply.started":"2022-05-30T11:08:59.522664Z","shell.execute_reply":"2022-05-30T11:08:59.543036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the generator\nnetG = Generator(ngpu).to(device)\n\n# Handle multi-gpu if desired\nif (device.type == 'cuda') and (ngpu > 1):\n    netG = nn.DataParallel(netG, list(range(ngpu)))\n\n# Apply the weights_init function to randomly initialize all weights\n#  to mean=0, stdev=0.02.\nnetG.apply(weights_init)\n\n# Print the model\nprint(netG)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:08:59.548142Z","iopub.execute_input":"2022-05-30T11:08:59.550293Z","iopub.status.idle":"2022-05-30T11:08:59.765996Z","shell.execute_reply.started":"2022-05-30T11:08:59.550258Z","shell.execute_reply":"2022-05-30T11:08:59.765093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, ngpu):\n        super(Discriminator, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            # input is (nc) x 128 x 128\n            nn.Conv2d(nc, ndf, 4, stride=2, padding=1, bias=False), \n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf) x 64 x 64\n            nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*2) x 32 x 32\n            nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*4) x 16 x 16 \n            nn.Conv2d(ndf * 4, ndf * 8, 4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*8) x 8 x 8\n            nn.Conv2d(ndf * 8, ndf * 16, 4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(ndf * 16),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*16) x 4 x 4\n            nn.Conv2d(ndf * 16, 1, 4, stride=1, padding=0, bias=False),\n            nn.Sigmoid()\n            # state size. 1\n        )\n    def forward(self, input):\n        return self.main(input)","metadata":{"id":"zLMOs5O51BdB","execution":{"iopub.status.busy":"2022-05-30T11:08:59.769667Z","iopub.execute_input":"2022-05-30T11:08:59.769923Z","iopub.status.idle":"2022-05-30T11:08:59.788851Z","shell.execute_reply.started":"2022-05-30T11:08:59.769889Z","shell.execute_reply":"2022-05-30T11:08:59.787955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the Discriminator\nnetD = Discriminator(ngpu).to(device)\n\n# Handle multi-gpu if desired\nif (device.type == 'cuda') and (ngpu > 1):\n    netD = nn.DataParallel(netD, list(range(ngpu)))\n\n# Apply the weights_init function to randomly initialize all weights\n#  to mean=0, stdev=0.2.\nnetD.apply(weights_init)\n\n# Print the model\nprint(netD)","metadata":{"id":"Qrnjt3qZ1IBj","execution":{"iopub.status.busy":"2022-05-30T11:08:59.791937Z","iopub.execute_input":"2022-05-30T11:08:59.792585Z","iopub.status.idle":"2022-05-30T11:08:59.843091Z","shell.execute_reply.started":"2022-05-30T11:08:59.792554Z","shell.execute_reply":"2022-05-30T11:08:59.842383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Перейдем теперь к обучению нашего GANа. Алгоритм обучения следующий:\n1. Учим дискриминатор:\n  * берем реальные изображения и присваиваем им метку 1\n  * генерируем изображения генератором и присваиваем им метку 0\n  * обучаем классификатор на два класса\n\n2. Учим генератор:\n  * генерируем изображения генератором и присваиваем им метку 0\n  * предсказываем дискриминаторором, реальное это изображение или нет\n\n\nВ качестве функции потерь берем бинарную кросс-энтропию","metadata":{"id":"MDHQaIzQ0B4S"}},{"cell_type":"code","source":"if use_pretrained:\n    netD.load_state_dict(torch.load('../input/model-weights50/discriminator50.pth'))\n    netG.load_state_dict(torch.load('../input/model-weights50/generator50.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:08:59.844139Z","iopub.execute_input":"2022-05-30T11:08:59.844662Z","iopub.status.idle":"2022-05-30T11:09:01.083262Z","shell.execute_reply.started":"2022-05-30T11:08:59.844601Z","shell.execute_reply":"2022-05-30T11:09:01.082532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize BCELoss function\ncriterion = nn.BCELoss()\n\n# Create batch of latent vectors that we will use to visualize\n#  the progression of the generator\nfixed_noise = torch.randn(64, nz, 1, 1, device=device)\n\n# Establish convention for real and fake labels during training\nreal_label = 1.\nfake_label = 0.\n\n# Setup Adam optimizers for both G and D\noptimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))","metadata":{"id":"H2u0HPmk3B78","execution":{"iopub.status.busy":"2022-05-28T13:56:57.507162Z","iopub.execute_input":"2022-05-28T13:56:57.507452Z","iopub.status.idle":"2022-05-28T13:56:57.514264Z","shell.execute_reply.started":"2022-05-28T13:56:57.50742Z","shell.execute_reply":"2022-05-28T13:56:57.513515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Loop\n\n# Lists to keep track of progress\nimg_list = []\nG_losses = []\nD_losses = []\niters = 0\n\nprint(\"Starting Training Loop...\")\n# For each epoch\nfor epoch in range(num_epochs):\n    # For each batch in the dataloader\n    for i, data in enumerate(dataloader, 0):\n\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        ## Train with all-real batch\n        netD.zero_grad()\n        # Format batch\n        real_cpu = data[0].to(device)\n        b_size = real_cpu.size(0)\n        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n        # Forward pass real batch through D\n        output = netD(real_cpu).view(-1)\n        # Calculate loss on all-real batch\n        errD_real = criterion(output, label)\n        # Calculate gradients for D in backward pass\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        ## Train with all-fake batch\n        # Generate batch of latent vectors\n        noise = torch.randn(b_size, nz, 1, 1, device=device)\n        # Generate fake image batch with G\n        fake = netG(noise)\n        label.fill_(fake_label)\n        # Classify all fake batch with D\n        output = netD(fake.detach()).view(-1)\n        # Calculate D's loss on the all-fake batch\n        errD_fake = criterion(output, label)\n        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        # Compute error of D as sum over the fake and the real batches\n        errD = errD_real + errD_fake\n        # Update D\n        optimizerD.step()\n\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        netG.zero_grad()\n        label.fill_(real_label)  # fake labels are real for generator cost\n        # Since we just updated D, perform another forward pass of all-fake batch through D\n        output = netD(fake).view(-1)\n        # Calculate G's loss based on this output\n        errG = criterion(output, label)\n        # Calculate gradients for G\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        # Update G\n        optimizerG.step()\n\n        # Output training stats\n        if i % 50 == 0:\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n                  % (epoch, num_epochs, i, len(dataloader),\n                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n\n        # Save Losses for plotting later\n        G_losses.append(errG.item())\n        D_losses.append(errD.item())\n\n        iters += 1","metadata":{"execution":{"iopub.status.busy":"2022-05-28T13:57:07.601135Z","iopub.execute_input":"2022-05-28T13:57:07.601449Z","iopub.status.idle":"2022-05-28T14:34:59.635899Z","shell.execute_reply.started":"2022-05-28T13:57:07.601406Z","shell.execute_reply":"2022-05-28T14:34:59.63491Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Постройте графики лосса для генератора и дискриминатора. Что вы можете сказать про эти графики?","metadata":{"id":"VkecCSn69DLe"}},{"cell_type":"code","source":"PATH = '/kaggle/working'\ntorch.save(netD.state_dict(), PATH + '/discriminator50.pth')\ntorch.save(netG.state_dict(), PATH + '/generator50.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-28T14:34:59.638106Z","iopub.execute_input":"2022-05-28T14:34:59.642437Z","iopub.status.idle":"2022-05-28T14:34:59.854686Z","shell.execute_reply.started":"2022-05-28T14:34:59.642396Z","shell.execute_reply":"2022-05-28T14:34:59.853766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(G_losses,label=\"G\")\nplt.plot(D_losses,label=\"D\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T13:08:54.157906Z","iopub.execute_input":"2022-05-28T13:08:54.15827Z","iopub.status.idle":"2022-05-28T13:08:54.5437Z","shell.execute_reply.started":"2022-05-28T13:08:54.158227Z","shell.execute_reply":"2022-05-28T13:08:54.542856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Часть 3. Генерация изображений (1 балл)","metadata":{"id":"kuL3ZZvX5G29"}},{"cell_type":"markdown","source":"Теперь давайте оценим качество получившихся изображений. Напишите функцию, которая выводит изображения, сгенерированные нашим генератором","metadata":{"id":"7q9_WFIl-Bf6"}},{"cell_type":"code","source":"# Grab a batch of real images from the dataloader\nreal_batch = next(iter(dataloader))\n\n# Plot the real images\nplt.figure(figsize=(20, 20))\nplt.subplot(1, 2, 1)\nplt.axis(\"off\")\nplt.title(\"Real Images\")\nplt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1, 2, 0)))\n\n# Plot the fake images from the last epoch\nplt.subplot(1, 2, 2)\nplt.axis(\"off\")\nplt.title(\"Fake Images\")\nplt.imshow(np.transpose(vutils.make_grid(netG(torch.randn(16, 100, 1, 1, device=device))[:64], padding=5, normalize=True).cpu(),(1, 2, 0)))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:09:51.328025Z","iopub.execute_input":"2022-05-30T11:09:51.328285Z","iopub.status.idle":"2022-05-30T11:09:59.600913Z","shell.execute_reply.started":"2022-05-30T11:09:51.328251Z","shell.execute_reply":"2022-05-30T11:09:59.600199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Как вам качество получившихся изображений?","metadata":{"id":"BHqPK3xs-Z-7"}},{"cell_type":"markdown","source":"## Часть 4. Leave-one-out-1-NN classifier accuracy (6 баллов)","metadata":{"id":"c0z41dA05KAa"}},{"cell_type":"markdown","source":"### 4.1. Подсчет accuracy (4 балла)","metadata":{"id":"2C9V8DHX_ipy"}},{"cell_type":"markdown","source":"Не всегда бывает удобно оценивать качество сгенерированных картинок глазами. В качестве альтернативы вам предлагается реализовать следующий подход:\n  * Сгенерировать столько же фейковых изображений, сколько есть настоящих в обучающей выборке. Присвоить фейковым метку класса 0, настоящим – 1.\n  * Построить leave-one-out оценку: обучить 1NN Classifier (`sklearn.neighbors.KNeighborsClassifier(n_neighbors=1)`) предсказывать класс на всех объектах, кроме одного, проверить качество (accuracy) на оставшемся объекте. В этом вам поможет `sklearn.model_selection.LeaveOneOut`","metadata":{"id":"9wT2uUb4_rku"}},{"cell_type":"code","source":"from tqdm import tqdm\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:17:38.478Z","iopub.execute_input":"2022-05-30T11:17:38.478808Z","iopub.status.idle":"2022-05-30T11:17:38.48291Z","shell.execute_reply.started":"2022-05-30T11:17:38.478761Z","shell.execute_reply":"2022-05-30T11:17:38.482043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"netG.eval()\n# @torch.no_grad()\nfake_images = netG(torch.randn(1000, nz, 1, 1, device=device))","metadata":{"id":"vsrgX9X4BfE0","execution":{"iopub.status.busy":"2022-05-30T11:17:38.631681Z","iopub.execute_input":"2022-05-30T11:17:38.631941Z","iopub.status.idle":"2022-05-30T11:17:38.650168Z","shell.execute_reply.started":"2022-05-30T11:17:38.631914Z","shell.execute_reply":"2022-05-30T11:17:38.649301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reshaped_fake = fake_images.reshape(fake_images.shape[0], -1)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:17:38.863211Z","iopub.execute_input":"2022-05-30T11:17:38.863764Z","iopub.status.idle":"2022-05-30T11:17:38.869069Z","shell.execute_reply.started":"2022-05-30T11:17:38.863727Z","shell.execute_reply":"2022-05-30T11:17:38.867968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_images = [i[0] for i in tqdm(dataset)][:1000]","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:17:39.128651Z","iopub.execute_input":"2022-05-30T11:17:39.129238Z","iopub.status.idle":"2022-05-30T11:20:00.920033Z","shell.execute_reply.started":"2022-05-30T11:17:39.129205Z","shell.execute_reply":"2022-05-30T11:20:00.919174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reshaped_real = torch.stack(real_images).reshape(fake_images.shape[0], -1)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:20:00.921705Z","iopub.execute_input":"2022-05-30T11:20:00.922051Z","iopub.status.idle":"2022-05-30T11:20:00.965052Z","shell.execute_reply.started":"2022-05-30T11:20:00.922001Z","shell.execute_reply":"2022-05-30T11:20:00.964267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert reshaped_real.shape == reshaped_fake.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:20:00.966239Z","iopub.execute_input":"2022-05-30T11:20:00.96659Z","iopub.status.idle":"2022-05-30T11:20:00.970788Z","shell.execute_reply.started":"2022-05-30T11:20:00.966549Z","shell.execute_reply":"2022-05-30T11:20:00.970042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = torch.concat([reshaped_real.cpu(), reshaped_fake.cpu()]).detach().numpy()\ny = torch.concat((torch.ones(1000), torch.zeros(1000))).numpy()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:20:30.860191Z","iopub.execute_input":"2022-05-30T11:20:30.860948Z","iopub.status.idle":"2022-05-30T11:20:31.144299Z","shell.execute_reply.started":"2022-05-30T11:20:30.860905Z","shell.execute_reply":"2022-05-30T11:20:31.142741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nscores = cross_val_score(KNeighborsClassifier(n_neighbors=1),\n                X,\n                y,\n                cv=LeaveOneOut())","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:20:31.147074Z","iopub.execute_input":"2022-05-30T11:20:31.150688Z","iopub.status.idle":"2022-05-30T11:40:32.593635Z","shell.execute_reply.started":"2022-05-30T11:20:31.150645Z","shell.execute_reply":"2022-05-30T11:40:32.592848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores.mean()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:43:07.102705Z","iopub.execute_input":"2022-05-30T11:43:07.103259Z","iopub.status.idle":"2022-05-30T11:43:07.108403Z","shell.execute_reply.started":"2022-05-30T11:43:07.103211Z","shell.execute_reply":"2022-05-30T11:43:07.107538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Что вы можете сказать о получившемся результате? Какой accuracy мы хотели бы получить и почему?","metadata":{"id":"jRU47nCzCVnP"}},{"cell_type":"markdown","source":"### 4.2. Визуализация распределений (2 балла)","metadata":{"id":"FqzHnPOACgoZ"}},{"cell_type":"markdown","source":"Давайте посмотрим на то, насколько похожи распределения настоящих и фейковых изображений. Для этого воспользуйтесь методом, снижающим размерность (к примеру, TSNE) и изобразите на графике разным цветом точки, соответствующие реальным и сгенерированным изображенияи","metadata":{"id":"EweiItWFDYO0"}},{"cell_type":"code","source":"tsne = TSNE(n_components=2)\ntsne_results = tsne.fit_transform(X)","metadata":{"id":"UZBJWkWdCepj","execution":{"iopub.status.busy":"2022-05-30T11:44:30.740246Z","iopub.execute_input":"2022-05-30T11:44:30.740829Z","iopub.status.idle":"2022-05-30T11:44:56.256684Z","shell.execute_reply.started":"2022-05-30T11:44:30.74079Z","shell.execute_reply":"2022-05-30T11:44:56.255829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.scatter(tsne_results, x=0, y=1, color=y.astype(str),labels={'0': 'tsne-2d-one', '1': 'tsne-2d-two'})\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T11:45:17.236091Z","iopub.execute_input":"2022-05-30T11:45:17.236364Z","iopub.status.idle":"2022-05-30T11:45:18.141426Z","shell.execute_reply.started":"2022-05-30T11:45:17.23633Z","shell.execute_reply":"2022-05-30T11:45:18.140786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Прокомментируйте получившийся результат:\n\nНеплохо получилось, очень похоже на гауссовое распределние, в двумерном пространстве картинки похожи между собой, скор, конечно, не 0.5, но и не все 3000 картиков использовались из-за долгих вычислений.\n\nГенератор работает неплохо. \n\n### Основные идеи по улучшению:\n\n1) Использовать вместо дискриминатора ResNet или ещё другую более актуальную сетку.\n\n2) Более сложный генератор с большим количеством слоев и карт активаций.\n\n3) MSE.\n\n4) Буфер для картинок и другие идеи отсюда: https://github.com/soumith/ganhacks .\n\n5) БОльший датасет, 3143 картинки - не очень много, сложная сетка будет запоминать данные.\n\n6) Improved Techniques for Training GANs https://arxiv.org/pdf/1606.03498.pdf .\n\n7) Пробовать готовые Ганы https://github.com/Zeleni9/pytorch-wgan/tree/master/models .\n\n","metadata":{"id":"ZVZe9tt8DuYh"}}]}